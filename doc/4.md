## 随手记

我们需要限制服务器节点发起连接到其他节点的连接数，因为过多的连接会降低服务器性能，虽然这样可以方便我们处理转发。但是当连接数不足时，就需要中继节点进行转发，而转发会产生不必要的延迟，这就涉及到一个折中问题：连接数和转发跳转的平衡。

在这里我们假定每个节点最多创建的连接数为N，则对于有M个节点的集群，假设一次转发延迟为a，则有最((M/2)/N)*a，其中((M/2)/N)向上取整。考虑到内网延迟比较低，所以可接受的挑战次数看实际部署决定。

而转发次数过高又会造成单个节点更高的转发流量，所以这又是一种权衡。

所以在最大连接数一定的情况下，节点规模越大，延迟越高，对带宽要求也就越高；而世界上没有完美的设计，所以我们没法实现无限扩展。

假设系统节点最大连接数为10，允许一次跳转，则最大节点数量为40，如果允许二次跳转，则为60，即允许的最大节点数等于(最大连接数 * (最大跳转数 + 1)) * 2，具体计算后面提及。

而单台节点可以扛住万级别连接，这里假设连接最大为100000，则搭配一级节点，即可实现十五亿连接，一级节点负责二级节点的流量转发，二级节点负责和客户端直连。

一级节点抗受的流量最差为Nb-b^2，其中b是一级节点上二级节点的数量，N为节点总数。这个值肯定小于N^2。此外还有转发数产生的过多流量，这是一个值得思考的模式选择。

所以最后的选择是通过限制最大连接数和分层节点来实现更大量的集群部署，且随着二级节点的增加，一级节点增加，系统跳转数增大，每个一级节点流量总量变得更大，这就对一级节点的性能和吞吐量提出了很高的要求。

2022-11-02

我又重新看了看QUIC以及UDP的实现，发现UDP不同于TCP的一点在于，它是可以在一个端口实现多连接的，即，面对多个远程连接，我们不需要绑定多个端口。

此外在群里请教过并发表了我的分层设计意见之后，上述的二级节点是可行的。但是为了减少开发难度，这点放在后续版本迭代。

关于之前准备采用的哈希环设计，这里决定废弃，原因在于：增加服务端开发难度，无法根据负载能力做出均衡。取而代之是把用户和节点ID的关系写入到消息头，要求发送方主动获取目标所在的节点ID，并添加到消息头。缺点是在连接迁移时需要进行广播通知，此外这里暴露了系统设计的原理。但是总的来说利大于弊。

关于设计上，每个用户(包括群)连接到的节点基本都是不变的，除非节点宕机或者负载过高。当映射关系变化时，balancer需要广播此消息，让此用户所在的每一个群的群任务去更新映射关系。

这里提到了群，群在创建之后，会尝试拉取用户列表，获取所有用户的节点ID，之后就不再拉取。所以要求某一用户映射关系变化时必须可以通知到对应的群聊去更新。群聊发送消息会直接向节点推送，而不论是否在线。

这里就需要节点可以调用balancer的方法去获取用户节点映射关系。原本打算使用msg体系，但是msg是一个异步消息设计，而这里需要同步获取，所以考虑使用rpc完成。其实封装msg设计也可以实现类似h3的同步，但是徒增成本。

那么内部到底哪里使用rpc，哪里使用msg呢？判断标准取决于同步/异步请求。